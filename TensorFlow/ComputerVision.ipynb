{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-03T03:48:36.660576Z",
     "start_time": "2024-06-03T03:46:13.913450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not read frame from the camera.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def main():\n",
    "    # Open a connection to the front camera (camera index 0)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video stream from the camera.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame from the camera.\")\n",
    "            break\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Video Stream', frame)\n",
    "\n",
    "        # Press 'q' to quit the video stream\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the capture when everything is done\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photo saved: photos/face_1717387258.jpg\n",
      "Photo saved: photos/face_1717387262.jpg\n",
      "Photo saved: photos/face_1717387265.jpg\n",
      "Photo saved: photos/face_1717387268.jpg\n",
      "Photo saved: photos/face_1717387271.jpg\n",
      "Photo saved: photos/face_1717387274.jpg\n",
      "Photo saved: photos/face_1717387277.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 73\u001B[0m\n\u001B[1;32m     70\u001B[0m     cv2\u001B[38;5;241m.\u001B[39mdestroyAllWindows()\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 73\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[4], line 24\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     20\u001B[0m last_captured_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;66;03m# Capture frame-by-frame\u001B[39;00m\n\u001B[0;32m---> 24\u001B[0m     ret, frame \u001B[38;5;241m=\u001B[39m \u001B[43mcap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ret:\n\u001B[1;32m     27\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError: Could not read frame from the camera.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "\n",
    "def main():\n",
    "    # Create a directory to save the photos\n",
    "    if not os.path.exists('photos'):\n",
    "        os.makedirs('photos')\n",
    "\n",
    "    # Load the Haar cascade file for face detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Open a connection to the front camera (camera index 0)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video stream from the camera.\")\n",
    "        return\n",
    "\n",
    "    last_captured_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Error: Could not read frame from the camera.\")\n",
    "            break\n",
    "\n",
    "        # Convert the frame to grayscale (face detection works better on grayscale images)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces in the frame\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "        # Draw rectangles around detected faces and add a label\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Draw rectangle around the face\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "            # Set label below the face\n",
    "            label = \"Face\"\n",
    "            label_size, base_line = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "            label_y = y + h + label_size[1] + 10\n",
    "\n",
    "            # Draw a filled rectangle behind the label text\n",
    "            cv2.rectangle(frame, (x, label_y - label_size[1] - 10), (x + label_size[0], label_y + base_line - 10), (255, 0, 0), cv2.FILLED)\n",
    "\n",
    "            # Put label text below the face\n",
    "            cv2.putText(frame, label, (x, label_y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "            # Take a photo every 3 seconds if a face is detected\n",
    "            current_time = time.time()\n",
    "            if current_time - last_captured_time >= 3:\n",
    "                # Save the photo with a timestamp\n",
    "                photo_filename = f\"photos/face_{int(current_time)}.jpg\"\n",
    "                cv2.imwrite(photo_filename, frame)\n",
    "                print(f\"Photo saved: {photo_filename}\")\n",
    "                last_captured_time = current_time\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Video Stream - Face Detection', frame)\n",
    "\n",
    "        # Press 'q' to quit the video stream\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the capture when everything is done\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T04:01:17.686771Z",
     "start_time": "2024-06-03T04:00:55.818577Z"
    }
   },
   "id": "9ed694b64c497865",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Function to preprocess the images\n",
    "def preprocess_images(image_paths):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for path in image_paths:\n",
    "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        images.append(image)\n",
    "        labels.append(int(os.path.basename(os.path.dirname(path))))\n",
    "\n",
    "    return images, np.array(labels)\n",
    "\n",
    "# Function to train the face recognition model\n",
    "def train_model(data_dir):\n",
    "    # Create a list of all image paths\n",
    "    image_paths = []\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "\n",
    "    # Preprocess the images\n",
    "    images, labels = preprocess_images(image_paths)\n",
    "\n",
    "    # Create LBPH face recognizer\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "    # Train the recognizer\n",
    "    recognizer.train(images, labels)\n",
    "\n",
    "    # Save the trained model\n",
    "    recognizer.save(\"trained_model.yml\")\n",
    "\n",
    "    print(\"Model trained and saved successfully.\")\n",
    "\n",
    "# Directory containing the dataset\n",
    "data_dir = \"./photos\"\n",
    "\n",
    "# Train the model\n",
    "train_model(data_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T04:28:35.273052Z",
     "start_time": "2024-06-03T04:28:35.108052Z"
    }
   },
   "id": "62ab3f4df7ae6760",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photo saved: photos_temp/face_1067457.jpg\n",
      "Photo saved: photos_temp/face_1067460.jpg\n",
      "Photo saved: photos_temp/face_1067463.jpg\n",
      "Photo saved: photos_temp/face_1067466.jpg\n",
      "Photo saved: photos_temp/face_1067469.jpg\n",
      "Photo saved: photos_temp/face_1067475.jpg\n",
      "Photo saved: photos_temp/face_1067478.jpg\n",
      "Photo saved: photos_temp/face_1067482.jpg\n",
      "Photo saved: photos_temp/face_1067485.jpg\n",
      "Photo saved: photos_temp/face_1067488.jpg\n",
      "Photo saved: photos_temp/face_1067491.jpg\n",
      "Photo saved: photos_temp/face_1067494.jpg\n",
      "Photo saved: photos_temp/face_1067497.jpg\n",
      "Photo saved: photos_temp/face_1067500.jpg\n",
      "Photo saved: photos_temp/face_1067503.jpg\n",
      "Photo saved: photos_temp/face_1067506.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 61\u001B[0m\n\u001B[1;32m     58\u001B[0m gray \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mcvtColor(frame, cv2\u001B[38;5;241m.\u001B[39mCOLOR_BGR2GRAY)\n\u001B[1;32m     60\u001B[0m \u001B[38;5;66;03m# Detect faces in the frame\u001B[39;00m\n\u001B[0;32m---> 61\u001B[0m faces \u001B[38;5;241m=\u001B[39m \u001B[43mface_cascade\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetectMultiScale\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscaleFactor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1.1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mminNeighbors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mminSize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;66;03m# Draw rectangles around detected faces and add a label\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (x, y, w, h) \u001B[38;5;129;01min\u001B[39;00m faces:\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;66;03m# Draw rectangle around the face\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Function to preprocess the images\n",
    "def preprocess_images(image_paths):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for path in image_paths:\n",
    "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        images.append(image)\n",
    "        labels.append(int(os.path.basename(os.path.dirname(path))))\n",
    "\n",
    "    return images, np.array(labels)\n",
    "\n",
    "# Function to train the face recognition model\n",
    "def train_model(data_dir):\n",
    "    # Create a list of all image paths\n",
    "    image_paths = []\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "\n",
    "    # Preprocess the images\n",
    "    images, labels = preprocess_images(image_paths)\n",
    "\n",
    "    # Create LBPH face recognizer\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "    # Train the recognizer\n",
    "    recognizer.train(images, labels)\n",
    "\n",
    "    return recognizer\n",
    "\n",
    "# Load data containing information about each person's face\n",
    "# Example: { 'id1': 'John', 'id2': 'Jane', ... }\n",
    "data = {1: 'Uttam'}\n",
    "\n",
    "# Train the face recognition model\n",
    "recognizer = train_model(\"photos\")\n",
    "\n",
    "# Initialize some variables\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "last_captured_time = 0\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame from the camera.\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale (face detection works better on grayscale images)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Draw rectangles around detected faces and add a label\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw rectangle around the face\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "        # Take a region of interest (ROI) for face recognition\n",
    "        face_roi = gray[y:y+h, x:x+w]\n",
    "\n",
    "        # Perform face recognition\n",
    "        label_id, confidence = recognizer.predict(face_roi)\n",
    "\n",
    "        # Map label ID to name\n",
    "        name = data.get(label_id, \"Unknown\")\n",
    "\n",
    "        # Display name below the face\n",
    "        cv2.putText(frame, name, (x, y+h+20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Take a photo every 3 seconds if a face is detected\n",
    "        current_time = cv2.getTickCount() / cv2.getTickFrequency()\n",
    "        if current_time - last_captured_time >= 3:\n",
    "            # Save the photo with a timestamp\n",
    "            photo_filename = f\"photos_temp/face_{int(current_time)}.jpg\"\n",
    "            cv2.imwrite(photo_filename, frame)\n",
    "            print(f\"Photo saved: {photo_filename}\")\n",
    "\n",
    "            last_captured_time = current_time\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video Stream - Face Detection', frame)\n",
    "\n",
    "    # Press 'q' to quit the video stream\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture when everything is done\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-03T04:57:53.753645Z",
     "start_time": "2024-06-03T04:57:02.036291Z"
    }
   },
   "id": "f668995ee0826bed",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bdbdb095c4d1dcfe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
